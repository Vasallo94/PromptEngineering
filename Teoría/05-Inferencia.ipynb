{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "from utils.funciones import preguntar_llama, preguntar_gpt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chair_review = \"\"\"\n",
    "Es una silla excelente, con muchas opciones de configuración incluyendo una impresionante configurabilidad de los reposabrazos aunque por desgracia no permite bloquear la posición horizontal de los reposabrazos ni el giro del cojín del reposabrazos. El soporte de la espalda es excelente, el asiento es muy cómodo y permite ajustar su posición bien sea adelantándolo o retrasándolo. El reposacabezas es muy configurable, lo puedes adelantar, retrasar, subir, bajar, aunque no puedes retirarlo. Adicionalmente tiene ajuste lumbar aunque solo moviendo una \"barra\" en el respaldo que añade algo más de soporte... Tiene un par de puntos \"malos\" por ejemplo no tiene un respaldo de rejilla por lo que si hace calor vas a sudar en la espalda, el otro punto \"malo\" es que no tiene un ajuste lumbar completo, no permite variar mucho la dureza y posición del soporte lumbar salvo la barra que solo añade un poquito de soporte adicional. Hinomi lo ha vuelto a hacer, la HI pro es una silla excelente, con un precio elevado pero que merece la pena si vas a pasar muchas horas delante de un ordenador, tu espalda te lo agradecerá a largo plazo. Sin duda es una de las mejores sillas del mercado. ¿Es cara? si, pero tu espalda te se lo merece.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Descripción del producto de GPT\n",
       "El sentimiento de la reseña es positivo."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Descripción del producto de LLAMA\n",
       "El sentimiento de esta reseña es generalmente POSITIVO y RECOMENDATORIO. El usuario está muy satisfecho con la silla \"HI Pro\" y destaca sus puntos fuertes, como su configurabilidad, el soporte de la espalda, el asiento cómodo y el reposacabezas configurable. Incluso considera que el precio elevado merece la pena si se pasa mucha tiempo delante de un ordenador."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sys_prompt = \"Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt sin preámbulos explicativos ni resúmenes finales.\"\n",
    "prompt = f\"\"\"\n",
    "¿Cuál es el sentimiento de la siguiente reseña de producto, que está delimitada con triple comillas invertidas?\n",
    "\n",
    "Reseña: '''{chair_review}'''\n",
    "\"\"\"\n",
    "response = preguntar_gpt(sys_prompt=sys_prompt, prompt=prompt)\n",
    "display(Markdown(f\"### Descripción del producto de GPT\\n{response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"### Descripción del producto de LLAMA\\n{preguntar_llama(sys_prompt=sys_prompt, prompt=prompt)}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Descripción del producto de GPT\n",
       "positivo"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Descripción del producto de LLAMA\n",
       "Positivo."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "¿Cuál es el sentimiento de la siguiente reseña de producto, que está delimitada con triple comillas invertidas?\n",
    "\n",
    "Reseña: '''{chair_review}'''\n",
    "\n",
    "Devuelve tu respuesta en una única palabra, ya sea \"positivo\", \"negativo\" o \"neutral\".\n",
    "\"\"\"\n",
    "response = preguntar_gpt(sys_prompt=sys_prompt, prompt=prompt)\n",
    "display(Markdown(f\"### Descripción del producto de GPT\\n{response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"### Descripción del producto de LLAMA\\n{preguntar_llama(sys_prompt=sys_prompt, prompt=prompt)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificación de emociones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Descripción del producto de GPT\n",
       "excelente, cómodo, impresionante, malo, elevado"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Descripción del producto de LLAMA\n",
       "alegría, satisfacción, sorpresa, gratitud, felicidad"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identifica una lista de emociones que el escritor de la reseña está expresando. Incluye no más de cinco elementos en la lista. Formatea tu respuesta como una lista de palabras en minúsculas separadas por comas.\n",
    "\n",
    "Reseña: '''{chair_review}'''\n",
    "\"\"\"\n",
    "response = preguntar_gpt(sys_prompt=sys_prompt, prompt=prompt)\n",
    "display(Markdown(f\"### Descripción del producto de GPT\\n{response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"### Descripción del producto de LLAMA\\n{preguntar_llama(sys_prompt=sys_prompt, prompt=prompt)}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Descripción del producto de GPT\n",
       "- satisfacción\n",
       "- decepción\n",
       "- comodidad\n",
       "- frustración\n",
       "- aprecio\n",
       "\n",
       "Justificación:\n",
       "\n",
       "- **satisfacción**: \"Es una silla excelente, con muchas opciones de configuración\"\n",
       "- **decepción**: \"por desgracia no permite bloquear la posición horizontal de los reposabrazos\"\n",
       "- **comodidad**: \"el asiento es muy cómodo y permite ajustar su posición\"\n",
       "- **frustración**: \"no tiene un ajuste lumbar completo, no permite variar mucho la dureza y posición del soporte lumbar\"\n",
       "- **aprecio**: \"sin duda es una de las mejores sillas del mercado\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Descripción del producto de LLAMA\n",
       "Aquí te presento la lista de emociones que el escritor está expresando:\n",
       "\n",
       "felicidad, satisfacción, decepción, frustración, contentamiento\n",
       "\n",
       "Justificaciones para cada emoción:\n",
       "\n",
       "- **felicidad**: \"Es una silla excelente... Hinomi lo ha vuelto a hacer\" (el usuario se muestra muy satisfecho con la calidad de la silla).\n",
       "- **satisfacción**: \"El soporte de la espalda es excelente, el asiento es muy cómodo...\" (el usuario está contento con las características positivas de la silla).\n",
       "- **decepción**: \"...no permite bloquear la posición horizontal de los reposabrazos... no tiene un respaldo de rejilla\" (el usuario se muestra decepcionado por las limitaciones que tiene la silla).\n",
       "- **frustración**: \"...no tienes un ajuste lumbar completo...\" (el usuario parece estar frustrado con la falta de un ajuste más amplio y variado del soporte lumbar).\n",
       "- **contentamiento**: \"Tu espalda te lo agradecerá a largo plazo. Sin duda es una de las mejores sillas del mercado\" (el usuario se siente contento al saber que la silla será buena para su salud a largo plazo)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identifica una lista de emociones que el escritor de la reseña está expresando. Incluye no más de cinco elementos en la lista. Formatea tu respuesta como una lista de palabras en minúsculas separadas por comas.\n",
    "\n",
    "Reseña: '''{chair_review}'''\n",
    "\n",
    "Justifica tu respuesta para cada emoción con una extracción de texto de la reseña que la respalde.\n",
    "\"\"\"\n",
    "response = preguntar_gpt(sys_prompt=sys_prompt, prompt=prompt)\n",
    "display(Markdown(f\"### Descripción del producto de GPT\\n{response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"### Descripción del producto de LLAMA\\n{preguntar_llama(sys_prompt=sys_prompt, prompt=prompt)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificación de ira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Descripción del producto de GPT\n",
       "no"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Descripción del producto de LLAMA\n",
       "Sí."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "¿Está el escritor de la reseña expresando ira?\n",
    "La reseña está delimitada con triple comillas invertidas.\n",
    "Si la respuesta es afirmativa, responde \"sí\". En caso contrario, responde \"no\".\n",
    "\n",
    "Reseña: '''{chair_review}'''\n",
    "\"\"\"\n",
    "response = preguntar_gpt(sys_prompt=sys_prompt, prompt=prompt)\n",
    "display(Markdown(f\"### Descripción del producto de GPT\\n{response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"### Descripción del producto de LLAMA\\n{preguntar_llama(sys_prompt=sys_prompt, prompt=prompt)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción del nombre del producto y la compañía de la reseña"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Descripción del producto de GPT\n",
       "```json\n",
       "{\n",
       "  \"Artículo\": \"HI pro\",\n",
       "  \"Marca\": \"Hinomi\"\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Descripción del producto de LLAMA\n",
       "```json\n",
       "{\n",
       "  \"Artículo\": \"HI pro\",\n",
       "  \"Marca\": \"Hinomi\"\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identifica los siguientes artículos de la reseña: \n",
    "- Artículo adquirido por el autor de la reseña\n",
    "- Empresa que fabricó el artículo\n",
    "\n",
    "La reseña está delimitada por tres comillas. \n",
    "Formatee su respuesta como un objeto JSON con \"Artículo\" y \"Marca\" como claves. \n",
    "Si la información no está presente, utilice \"desconocido\" como valor.\n",
    "\n",
    "Haz tu respuesta lo más corta posible.\n",
    "  \n",
    "Texto de la reseña: '''{chair_review}'''\n",
    "\"\"\"\n",
    "response = preguntar_gpt(sys_prompt=sys_prompt, prompt=prompt)\n",
    "display(Markdown(f\"### Descripción del producto de GPT\\n{response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"### Descripción del producto de LLAMA\\n{preguntar_llama(sys_prompt=sys_prompt, prompt=prompt)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multitasking en un solo prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Descripción del producto de GPT\n",
       "```json\n",
       "{\n",
       "  \"Sentimiento\": \"positivo\",\n",
       "  \"Enfado\": false,\n",
       "  \"Artículo\": \"silla\",\n",
       "  \"Marca\": \"Hinomi\"\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Descripción del producto de LLAMA\n",
       "```json\n",
       "{\n",
       "  \"Sentimiento\": \"positivo\",\n",
       "  \"Enfado\": false,\n",
       "  \"Artículo\": \"silla\",\n",
       "  \"Marca\": \"Hinomi\"\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identifica los siguientes elementos del texto de la reseña: \n",
    "- Sentimiento (positivo o negativo)\n",
    "- ¿Expresa enfado el autor de la crítica? (verdadero o falso)\n",
    "- Artículo adquirido por el autor de la reseña\n",
    "- Empresa que fabricó el artículo\n",
    "\n",
    "La reseña se delimita con tres comillas.\n",
    "Formatea tu respuesta como un objeto JSON con \"Sentimiento\", \"Enfado\", \"Artículo\" y \"Marca\" como claves.\n",
    "Si la información no está presente, utilice \"desconocido\" como valor.\n",
    "Haz tu respuesta lo más corta posible.\n",
    "Formatea el valor de Ira como un booleano.\n",
    "\n",
    "Reseña: '''{chair_review}'''\n",
    "\"\"\"\n",
    "response = preguntar_gpt(sys_prompt=sys_prompt, prompt=prompt)\n",
    "display(Markdown(f\"### Descripción del producto de GPT\\n{response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"### Descripción del producto de LLAMA\\n{preguntar_llama(sys_prompt=sys_prompt, prompt=prompt)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infiriendo topicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Sora es un sistema de inteligencia artificial creado por OpenAI, la misma empresa que ha creado otros sistemas conocidos como ChatGPT o DALL-E. En este caso, es una IA que genera vídeos a partir de texto, de forma que tú le escribes lo que quieres ver mediante un prompt o comando textual, y la generará de la nada.\n",
    "Esta inteligencia artificial es muy similar a los modelos que crean imágenes a partir de texto, y que a la vez se basa en parte de la tecnología de modelos de lenguaje como GPT. Este sistema es capaz de entender lo que le pides con un lenguaje natural, ya que ha sido entrenada para entender la manera en las que solemos hablar y cómo nos expresamos para pedir o preguntar algo.\n",
    "Después de entender lo que le has pedido en un prompt, Sora podrá generar vídeos en los que se vea en movimiento lo que le has pedido, lo que supone un enorme paso más con respecto a simplemente crear imágenes.\n",
    "Esto lo ha conseguido porque es un modelo entrenado con una enorme biblioteca de vídeos, de forma que sabe reconocer movimientos, descripciones y cualquier cosa que le pidas, y será capaz de recrearlos en vídeo. Sabrá a lo que te refieres cuando le hables de tipos de personas, de vestimenta, de accesorios o de efectos visuales.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Descripción del producto de GPT\n",
       "[inteligencia artificial, generación de vídeos, tecnología de modelos, comprensión de lenguaje, biblioteca de vídeos]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Descripción del producto de LLAMA\n",
       "Sora es un sistema de inteligencia artificial creado por OpenAI, la misma empresa que ha creado otros sistemas conocidos como ChatGPT o DALL-E. En este caso, es una IA que genera vídeos a partir de texto, de forma que tú le escribes lo que quieres ver mediante un prompt o comando textual, y la generará de la nada.\n",
       "Esta inteligencia artificial es muy similar a los modelos que crean imágenes a partir de texto, y que a la vez se basa en parte de la tecnología de modelos de lenguaje como GPT. Este sistema es capaz de entender lo que le pides con un lenguaje natural, ya que ha sido entrenada para entender la manera en las que solemos hablar y cómo nos expresamos para pedir o preguntar algo.\n",
       "Después de entender lo que le has pedido en un prompt, Sora podrá generar vídeos en los que se vea en movimiento lo que le has pedido, lo que supone un enorme paso más con respecto a simplemente crear imágenes.\n",
       "Esto lo ha conseguido porque es un modelo entrenado con una enorme biblioteca de vídeos, de forma que sabe reconocer movimientos, descripciones y cualquier cosa que le pidas, y será capaz de recrearlos en vídeo. Sabrá a lo que te refieres cuando le hables de tipos de personas, de vestimenta, de accesorios o de efectos visuales.\n",
       "\n",
       "[Modelo, Inteligencia artificial, Videos, Lenguaje natural, Biblioteca]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determina cinco temas que se están discutiendo en el siguiente texto, que está delimitado por triple comillas invertidas.\n",
    "\n",
    "Haz que cada tema tenga una o dos palabras de longitud.\n",
    "\n",
    "Formato de respuesta: lista de elementos separados por comas: [tema1, tema2, tema3, tema4, tema5]\n",
    "\n",
    "Texto de ejemplo: '''{text}'''\n",
    "\"\"\"\n",
    "response = preguntar_gpt(sys_prompt=sys_prompt, prompt=prompt)\n",
    "display(Markdown(f\"### Descripción del producto de GPT\\n{response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"### Descripción del producto de LLAMA\\n{preguntar_llama(sys_prompt=sys_prompt, prompt=prompt)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tu turno de experimentar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
