{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "import sys\n",
    "sys.path.append('../utils/')\n",
    "from funciones import preguntar_llama, preguntar_gpt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chair_review = \"\"\"\n",
    "Es una silla excelente, con muchas opciones de configuración incluyendo una impresionante configurabilidad de los reposabrazos aunque por desgracia no permite bloquear la posición horizontal de los reposabrazos ni el giro del cojín del reposabrazos. El soporte de la espalda es excelente, el asiento es muy cómodo y permite ajustar su posición bien sea adelantándolo o retrasándolo. El reposacabezas es muy configurable, lo puedes adelantar, retrasar, subir, bajar, aunque no puedes retirarlo. Adicionalmente tiene ajuste lumbar aunque solo moviendo una \"barra\" en el respaldo que añade algo más de soporte... Tiene un par de puntos \"malos\" por ejemplo no tiene un respaldo de rejilla por lo que si hace calor vas a sudar en la espalda, el otro punto \"malo\" es que no tiene un ajuste lumbar completo, no permite variar mucho la dureza y posición del soporte lumbar salvo la barra que solo añade un poquito de soporte adicional. Hinomi lo ha vuelto a hacer, la HI pro es una silla excelente, con un precio elevado pero que merece la pena si vas a pasar muchas horas delante de un ordenador, tu espalda te lo agradecerá a largo plazo. Sin duda es una de las mejores sillas del mercado. ¿Es cara? si, pero tu espalda te se lo merece.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Respuesta de GPT\n",
       "El sentimiento de la reseña es positivo y entusiasta hacia la silla, destacando sus numerosas opciones de configuración y su excelente soporte para la espalda. A pesar de mencionar algunos puntos negativos, como la falta de bloqueo en ciertas posiciones y la ausencia de respaldo de rejilla, el tono general es de satisfacción y recomendación hacia el producto."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de LLAMA\n",
       "La reseña es positiva."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "¿Cuál es el sentimiento de la siguiente reseña de producto, que está delimitada con triple comillas invertidas?\n",
    "\n",
    "Reseña: '''{chair_review}'''\n",
    "\"\"\"\n",
    "response = preguntar_gpt(prompt)\n",
    "display(Markdown(f\"### Respuesta de GPT\\n{response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"### Respuesta de LLAMA\\n{preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt sin preámbulos explicativos ni resúmenes finales.', prompt)}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Respuesta de GPT\n",
       "Positivo"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de LLAMA\n",
       "Positivo"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "¿Cuál es el sentimiento de la siguiente reseña de producto, que está delimitada con triple comillas invertidas?\n",
    "\n",
    "Reseña: '''{chair_review}'''\n",
    "\n",
    "Devuelve tu respuesta en una única palabra, ya sea \"positivo\", \"negativo\" o \"neutral\".\n",
    "\"\"\"\n",
    "response = preguntar_gpt(prompt)\n",
    "display(Markdown(f\"### Respuesta de GPT\\n{response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"### Respuesta de LLAMA\\n{preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt sin preámbulos explicativos ni resúmenes finales.', prompt)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificación de emociones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Respuesta de GPT\n",
       "satisfacción, impresionante, excelente, configurable, elevado"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de LLAMA\n",
       "alegría, satisfacción, entusiasmo, crítica, admiración"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identifica una lista de emociones que el escritor de la reseña está expresando. Incluye no más de cinco elementos en la lista. Formatea tu respuesta como una lista de palabras en minúsculas separadas por comas.\n",
    "\n",
    "Reseña: '''{chair_review}'''\n",
    "\"\"\"\n",
    "response = preguntar_gpt(prompt)\n",
    "display(Markdown(f\"### Respuesta de GPT\\n{response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"### Respuesta de LLAMA\\n{preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt sin preámbulos explicativos ni resúmenes finales.', prompt)}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Respuesta de GPT\n",
       "- impresionante configurabilidad de los reposabrazos\n",
       "  - soporte de la espalda es excelente\n",
       "  - asiento es muy cómodo\n",
       "  - reposacabezas es muy configurable\n",
       "  - Hinomi lo ha vuelto a hacer, la HI pro es una silla excelente\n",
       "\n",
       "Estas emociones se pueden identificar en la reseña a través de frases como \"impresionante configurabilidad\", \"excelente soporte de la espalda\", \"muy cómodo\", \"muy configurable\" y \"una silla excelente\". Estas expresiones reflejan admiración, satisfacción y aprobación por las características de la silla."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de LLAMA\n",
       "alegría, satisfacción, crítica, enfado, admiración\n",
       "\n",
       "(satisfacción): \"Hinomi lo ha vuelto a hacer, la HI pro es una silla excelente...\"\n",
       "(alegría): \"la HI pro es una de las mejores sillas del mercado\"\n",
       "(crítica): \"no permite bloquear la posición horizontal de los reposabrazos ni el giro del cojín del reposabrazos\", \"no tiene un respaldo de rejilla\", \"no tiene un ajuste lumbar completo\"\n",
       "(enfado): \"por desgracia\"\n",
       "(admiración): \"tiene ajuste lumbar aunque solo moviendo una 'barra' en el respaldo que añade algo más de soporte...\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identifica una lista de emociones que el escritor de la reseña está expresando. Incluye no más de cinco elementos en la lista. Formatea tu respuesta como una lista de palabras en minúsculas separadas por comas.\n",
    "\n",
    "Reseña: '''{chair_review}'''\n",
    "\n",
    "Justifica tu respuesta para cada emoción con una extracción de texto de la reseña que la respalde.\n",
    "\"\"\"\n",
    "response = preguntar_gpt(prompt)\n",
    "display(Markdown(f\"### Respuesta de GPT\\n{response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"### Respuesta de LLAMA\\n{preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt sin preámbulos explicativos ni resúmenes finales.', prompt)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificación de ira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Respuesta de GPT\n",
       "no"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de LLAMA\n",
       "No"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "¿Está el escritor de la reseña expresando ira?\n",
    "La reseña está delimitada con triple comillas invertidas.\n",
    "Si la respuesta es afirmativa, responde \"sí\". En caso contrario, responde \"no\".\n",
    "\n",
    "Reseña: '''{chair_review}'''\n",
    "\"\"\"\n",
    "response = preguntar_gpt(prompt)\n",
    "display(Markdown(f\"### Respuesta de GPT\\n{response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"### Respuesta de LLAMA\\n{preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt sin preámbulos explicativos ni resúmenes finales.', prompt)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción del nombre del producto y la compañía de la reseña"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Respuesta de GPT\n",
       "{\n",
       "    \"Artículo\": \"silla\",\n",
       "    \"Marca\": \"Hinomi\"\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de LLAMA\n",
       "{\n",
       "  \"Artículo\": \"silla\",\n",
       "  \"Marca\": \"HI\"\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identifica los siguientes artículos de la reseña: \n",
    "- Artículo adquirido por el autor de la reseña\n",
    "- Empresa que fabricó el artículo\n",
    "\n",
    "La reseña está delimitada por tres comillas. \n",
    "Formatee su respuesta como un objeto JSON con \"Artículo\" y \"Marca\" como claves. \n",
    "Si la información no está presente, utilice \"desconocido\" como valor.\n",
    "\n",
    "Haz tu respuesta lo más corta posible.\n",
    "  \n",
    "Texto de la reseña: '''{chair_review}'''\n",
    "\"\"\"\n",
    "response = preguntar_gpt(prompt)\n",
    "display(Markdown(f\"### Respuesta de GPT\\n{response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"### Respuesta de LLAMA\\n{preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt sin preámbulos explicativos ni resúmenes finales.', prompt)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multitasking en un solo prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Respuesta de GPT\n",
       "{\n",
       "    \"Sentimiento\": \"positivo\",\n",
       "    \"Enfado\": false,\n",
       "    \"Artículo\": \"desconocido\",\n",
       "    \"Marca\": \"Hinomi\"\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de LLAMA\n",
       "{\n",
       "  \"Sentimiento\": \"positivo\",\n",
       "  \"Enfado\": false,\n",
       "  \"Artículo\": desconocido,\n",
       "  \"Marca\": \"HI\"\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identifica los siguientes elementos del texto de la reseña: \n",
    "- Sentimiento (positivo o negativo)\n",
    "- ¿Expresa enfado el autor de la crítica? (verdadero o falso)\n",
    "- Artículo adquirido por el autor de la reseña\n",
    "- Empresa que fabricó el artículo\n",
    "\n",
    "La reseña se delimita con tres comillas.\n",
    "Formatea tu respuesta como un objeto JSON con \"Sentimiento\", \"Enfado\", \"Artículo\" y \"Marca\" como claves.\n",
    "Si la información no está presente, utilice \"desconocido\" como valor.\n",
    "Haz tu respuesta lo más corta posible.\n",
    "Formatea el valor de Ira como un booleano.\n",
    "\n",
    "Reseña: '''{chair_review}'''\n",
    "\"\"\"\n",
    "response = preguntar_gpt(prompt)\n",
    "display(Markdown(f\"### Respuesta de GPT\\n{response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"### Respuesta de LLAMA\\n{preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt sin preámbulos explicativos ni resúmenes finales.', prompt)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infiriendo topicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Sora es un sistema de inteligencia artificial creado por OpenAI, la misma empresa que ha creado otros sistemas conocidos como ChatGPT o DALL-E. En este caso, es una IA que genera vídeos a partir de texto, de forma que tú le escribes lo que quieres ver mediante un prompt o comando textual, y la generará de la nada.\n",
    "Esta inteligencia artificial es muy similar a los modelos que crean imágenes a partir de texto, y que a la vez se basa en parte de la tecnología de modelos de lenguaje como GPT. Este sistema es capaz de entender lo que le pides con un lenguaje natural, ya que ha sido entrenada para entender la manera en las que solemos hablar y cómo nos expresamos para pedir o preguntar algo.\n",
    "Después de entender lo que le has pedido en un prompt, Sora podrá generar vídeos en los que se vea en movimiento lo que le has pedido, lo que supone un enorme paso más con respecto a simplemente crear imágenes.\n",
    "Esto lo ha conseguido porque es un modelo entrenado con una enorme biblioteca de vídeos, de forma que sabe reconocer movimientos, descripciones y cualquier cosa que le pidas, y será capaz de recrearlos en vídeo. Sabrá a lo que te refieres cuando le hables de tipos de personas, de vestimenta, de accesorios o de efectos visuales.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Respuesta de GPT\n",
       "[IA, vídeos, texto, GPT, entrenamiento]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de LLAMA\n",
       "\"Sora, IA, video\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determina cinco temas que se están discutiendo en el siguiente texto, que está delimitado por triple comillas invertidas.\n",
    "\n",
    "Haz que cada tema tenga una o dos palabras de longitud.\n",
    "\n",
    "Formato de respuesta: lista de elementos separados por comas: [tema1, tema2, tema3, tema4, tema5]\n",
    "\n",
    "Texto de ejemplo: '''{text}'''\n",
    "\"\"\"\n",
    "response = preguntar_gpt(prompt)\n",
    "display(Markdown(f\"### Respuesta de GPT\\n{response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"### Respuesta de LLAMA\\n{preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt sin preámbulos explicativos ni resúmenes finales.', prompt)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tu turno de experimentar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
