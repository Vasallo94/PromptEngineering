{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principios básicos del prompting\n",
    "\n",
    "1. Los prompts deben ser sencillos y claros. No es necesario escribir un párrafo entero para obtener una respuesta.\n",
    "2. Dale al modelo tiempo para \"pensar\" en la respuesta. No le des un prompt y esperes una respuesta inmediata."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Teoría/02-Principios basicos de prompting.ipynb
   "execution_count": 6,
=======
   "execution_count": 1,
>>>>>>> origin/main:02-Principios basicos de prompting.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
<<<<<<< HEAD:Teoría/02-Principios basicos de prompting.ipynb
    "import sys\n",
    "sys.path.append('../utils/')\n",
    "from funciones import preguntar_llama, preguntar_gpt\n"
=======
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "auth_token = os.getenv(\"AUTH_TOKEN\")\n",
    "\n",
    "\n",
    "headers = {\n",
    "  'Content-Type': 'application/json',\n",
    "  'Authorization': f\"Bearer {auth_token}\"\n",
    "}\n",
    "url = 'https://api.awanllm.com/v1/chat/completions' # URL for the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para llamar a la API de LLMCloud para preguntarle a LLAMA\n",
    "def preguntar_llama(sys_prompt, prompt):\n",
    "    payload = json.dumps({\n",
    "        \"model\": \"Meta-Llama-3-8B-Instruct\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": sys_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "      })\n",
    "    return requests.request(\"POST\", url, headers=headers, data=payload).json()['choices'][0]['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo-0125\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.1,\n",
    "        max_tokens=256,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    return response.choices[0].message.content"
>>>>>>> origin/main:02-Principios basicos de prompting.ipynb
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tácticas\n",
    "\n",
    "1. Utiliza delimitadores para indicar cómo distinguir partes del input.\n",
    "    Delimitadores pueden ser ```, \"\"\", < >, `<tag> </tag>`, etc."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Teoría/02-Principios basicos de prompting.ipynb
   "execution_count": 7,
=======
   "execution_count": 4,
>>>>>>> origin/main:02-Principios basicos de prompting.ipynb
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
<<<<<<< HEAD:Teoría/02-Principios basicos de prompting.ipynb
       "**Respuesta GPT:** En resumen, la temperatura en un Modelo de Lenguaje de Gran Escala afecta la variabilidad de las respuestas, siendo más deterministas a menor temperatura y más creativas o variadas al incrementarla, con repercusiones en la precisión y brevedad de las respuestas para tareas objetivas y en la creatividad para actividades más creativas como la poesía."
=======
       "**Respuesta GPT:** A menor temperatura en un Modelo de Lenguaje de Gran Escala (LLM) los resultados tienden a ser más deterministas, optando por el siguiente token de mayor probabilidad, mientras que incrementar la temperatura introduce mayor variabilidad en las respuestas, promoviendo resultados más variados o creativos al incrementar la posibilidad de elegir diferentes tokens como opciones, siendo recomendado un valor de temperatura reducido para respuestas certeras y breves en tareas como preguntas y respuestas basadas en información objetiva, pero ventajoso aumentar el valor de la temperatura en la creación de poesía u otras actividades creativas, aunque el aumento en la temperatura puede generar alucinaciones."
>>>>>>> origin/main:02-Principios basicos de prompting.ipynb
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
<<<<<<< HEAD:Teoría/02-Principios basicos de prompting.ipynb
      "\n",
      "Intento 1 fallido. Error: 500 Server Error: Internal Server Error for url: https://api.awanllm.com/v1/chat/completions\n",
      "No se pudo completar la solicitud después de varios intentos.\n"
=======
      "\n"
>>>>>>> origin/main:02-Principios basicos de prompting.ipynb
     ]
    },
    {
     "data": {
      "text/markdown": [
<<<<<<< HEAD:Teoría/02-Principios basicos de prompting.ipynb
       "**Respuesta de LLAMA:** None"
=======
       "**Respuesta de LLAMA:** En un Modelo de Lenguaje de Gran Escala, una temperatura baja produce resultados más deterministas y predeterminados, mientras que una temperatura alta introduce variabilidad y creatividad en las respuestas, siendo recomendable utilizar temperaturas bajas para preguntas y respuestas objetivas y altas para creación literaria."
>>>>>>> origin/main:02-Principios basicos de prompting.ipynb
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definimos el texto\n",
    "text = \"\"\"En esencia, a menor temperatura en un Modelo de Lenguaje de Gran Escala (LLM), los resultados tienden a ser más deterministas. Esto implica que el modelo optará con más frecuencia por el siguiente token de mayor probabilidad. Incrementar la temperatura introduce mayor variabilidad en las respuestas, lo que promueve resultados más variados o creativos. Básicamente, al elevar la temperatura, se incrementa la posibilidad de elegir diferentes tokens como opciones. Desde un punto de vista práctico, en tareas como preguntas y respuestas basadas en información objetiva, se sugiere utilizar un valor de temperatura reducido para lograr respuestas más certeras y breves. Sin embargo, en la creación de poesía o en otras actividades creativas, puede resultar ventajoso aumentar el valor de la temperatura. El aumento en la temperatura puede generar alucinaciones.\"\"\"\n",
    "\n",
    "# Definimos el prompt\n",
    "prompt = f\"Resume el texto delimitado por las triples comillas en una sola oración: {text}\"\n",
    "\n",
    "# Obtenemos la respuesta\n",
    "response = preguntar_gpt(prompt)\n",
    "display(Markdown(f\"**Respuesta GPT:** {response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"**Respuesta de LLAMA:** {preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt', prompt=prompt)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. JSON, HTML, XML, YAML, etc. son formatos que el modelo puede entender y que pueden ayudar a estructurar el input."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Teoría/02-Principios basicos de prompting.ipynb
   "execution_count": 8,
=======
   "execution_count": 5,
>>>>>>> origin/main:02-Principios basicos de prompting.ipynb
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Respuesta GPT:** {\n",
<<<<<<< HEAD:Teoría/02-Principios basicos de prompting.ipynb
      "  \"libros\": [\n",
      "    {\n",
      "      \"book_id\": 1,\n",
      "      \"título\": \"El secreto de las estrellas fugaces\",\n",
      "      \"autor\": \"Olivia Luna\",\n",
      "      \"género\": \"Fantasía\"\n",
      "    },\n",
      "    {\n",
      "      \"book_id\": 2,\n",
      "      \"título\": \"El enigma del reloj de arena\",\n",
      "      \"autor\": \"Maximiliano Sol\",\n",
      "      \"género\": \"Misterio\"\n",
      "    },\n",
      "    {\n",
      "      \"book_id\": 3,\n",
      "      \"título\": \"La melodía de la lluvia eterna\",\n",
      "      \"autor\": \"Camila Aurora\",\n",
      "      \"género\": \"Romance\"\n",
      "    }\n",
      "  ]\n",
=======
      "    \"books\": [\n",
      "        {\n",
      "            \"book_id\": 1,\n",
      "            \"título\": \"El misterio de la isla perdida\",\n",
      "            \"autor\": \"María García\",\n",
      "            \"género\": \"Misterio\"\n",
      "        },\n",
      "        {\n",
      "            \"book_id\": 2,\n",
      "            \"título\": \"El secreto de la montaña encantada\",\n",
      "            \"autor\": \"Juan Pérez\",\n",
      "            \"género\": \"Aventura\"\n",
      "        },\n",
      "        {\n",
      "            \"book_id\": 3,\n",
      "            \"título\": \"La magia de la noche estrellada\",\n",
      "            \"autor\": \"Ana López\",\n",
      "            \"género\": \"Fantasía\"\n",
      "        }\n",
      "    ]\n",
>>>>>>> origin/main:02-Principios basicos de prompting.ipynb
      "}\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
<<<<<<< HEAD:Teoría/02-Principios basicos de prompting.ipynb
      "Intento 1 fallido. Error: 502 Server Error: Bad Gateway for url: https://api.awanllm.com/v1/chat/completions. Error de Gateway.\n",
      "Reintentando en 10 segundos...\n",
      "Intento 2 fallido. Error: 500 Server Error: Internal Server Error for url: https://api.awanllm.com/v1/chat/completions\n",
      "No se pudo completar la solicitud después de varios intentos.\n",
      "**Respuesta de LLAMA:** None\n"
=======
      "**Respuesta de LLAMA:** Aquí tienes la lista de títulos de libros inventados:\n",
      "\n",
      "```\n",
      "[\n",
      "  {\n",
      "    \"book_id\": \"1\",\n",
      "    \"título\": \"El misterio del jardín de cristal\",\n",
      "    \"autor\": \"Ana María García\",\n",
      "    \"género\": \"Misterio\"\n",
      "  },\n",
      "  {\n",
      "    \"book_id\": \"2\",\n",
      "    \"título\": \"La ciudad de los sueños perdidos\",\n",
      "    \"autor\": \"Juan Carlos Rodríguez\",\n",
      "    \"género\": \"Ciencia Ficción\"\n",
      "  },\n",
      "  {\n",
      "    \"book_id\": \"3\",\n",
      "    \"título\": \"El secreto de la cueva de piedra\",\n",
      "    \"autor\": \"María Luisa Hernández\",\n",
      "    \"género\": \"Aventura\"\n",
      "  }\n",
      "]\n",
      "```\n"
>>>>>>> origin/main:02-Principios basicos de prompting.ipynb
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Genera una lista de tres títulos de libros inventados junto con sus autores y géneros. Proporciónelos en formato JSON con las siguientes claves: book_id, título, autor, género\"\"\"\n",
    "response = preguntar_gpt(prompt)\n",
    "\n",
    "print(f\"**Respuesta GPT:** {response}\")\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "print(f\"**Respuesta de LLAMA:** {preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt', prompt=prompt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Pídele al modelo que verifique si se están cumpliendo ciertas condiciones."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Teoría/02-Principios basicos de prompting.ipynb
   "execution_count": 9,
=======
   "execution_count": 6,
>>>>>>> origin/main:02-Principios basicos de prompting.ipynb
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
<<<<<<< HEAD:Teoría/02-Principios basicos de prompting.ipynb
       "**Respuesta GPT:** Paso 1 - Asegúrate de que la máquina esté encendida y lista para usar.\n",
       "\n",
       "Paso 2 - Muele los granos de café según el grosor deseado y colócalos en el portafiltro.\n",
       "\n",
       "Paso 3 - Compacta el café con el tampador para garantizar una extracción uniforme.\n",
       "\n",
       "Paso 4 - Ajusta la cantidad de café según tu preferencia y coloca el portafiltro en la máquina.\n",
       "\n",
       "Paso 5 - Activa la máquina y espera a que el café se extraiga lentamente, disfrutando del aroma que llena el aire.\n",
       "\n",
       "¡Y voilà! Disfruta de tu aromático y delicioso café espresso."
=======
       "**Respuesta GPT:** Paso 1 - Asegurarse de que la máquina esté encendida y lista para usar.\n",
       "\n",
       "Paso 2 - Moler los granos de café según el grosor deseado y colocarlos en el portafiltro.\n",
       "\n",
       "Paso 3 - Compactar el café con el tampador para garantizar una extracción uniforme.\n",
       "\n",
       "Paso 4 - Ajustar la cantidad de café según la preferencia y colocar el portafiltro en la máquina.\n",
       "\n",
       "Paso 5 - Activar la máquina y esperar a que el café se extraiga lentamente, disfrutando del aroma que llena el aire.\n",
       "\n",
       "Paso 6 - ¡Y voilà! Disfrutar de tu aromático y delicioso café espresso."
>>>>>>> origin/main:02-Principios basicos de prompting.ipynb
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
<<<<<<< HEAD:Teoría/02-Principios basicos de prompting.ipynb
      "\n",
      "Intento 1 fallido. Error: 500 Server Error: Internal Server Error for url: https://api.awanllm.com/v1/chat/completions\n",
      "No se pudo completar la solicitud después de varios intentos.\n"
=======
      "\n"
>>>>>>> origin/main:02-Principios basicos de prompting.ipynb
     ]
    },
    {
     "data": {
      "text/markdown": [
<<<<<<< HEAD:Teoría/02-Principios basicos de prompting.ipynb
       "**Respuesta de LLAMA:** None"
=======
       "**Respuesta de LLAMA:** Paso 1 - Asegúrate de que la máquina esté encendida y lista para usar.\n",
       "\n",
       "Paso 2 - Muele los granos de café según el grosor deseado y colócalos en el portafiltro.\n",
       "\n",
       "Paso 3 - Compacta el café con el tampador para garantizar una extracción uniforme.\n",
       "\n",
       "Paso 4 - Ajusta la cantidad de café según tu preferencia y coloca el portafiltro en la máquina.\n",
       "\n",
       "Paso 5 - Activa la máquina y espera a que el café se extraiga lentamente, disfrutando del aroma que llena el aire.\n",
       "\n",
       "(Note: No hay más pasos después de este)"
>>>>>>> origin/main:02-Principios basicos de prompting.ipynb
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_1 = \"\"\"Preparar una exquisita taza de café en una máquina espresso es un proceso sencillo. En primer lugar, asegúrate de que la máquina esté encendida y lista para usar. Luego, muele los granos de café según el grosor deseado y colócalos en el portafiltro. Compacta el café con el tampador para garantizar una extracción uniforme. Ajusta la cantidad de café según tu preferencia y coloca el portafiltro en la máquina. Activa la máquina y espera a que el café se extraiga lentamente, disfrutando del aroma que llena el aire. ¡Y voilà! Disfruta de tu aromático y delicioso café espresso.\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Vas a recibir un texto delimitado por triples comillas.\n",
    "Si contiene una secuencia de instrucciones, reescribe esas instrucciones en el siguiente formato:\n",
    "\n",
    "Paso 1 - ...\\n\n",
    "Paso 2 - ...\\n\n",
    "…\n",
    "Paso N - ... \\n\n",
    "\n",
    "Si el texto no contiene una secuencia de instrucciones, entonces simplemente escribe \"No se proporcionaron pasos.\"\n",
    "\n",
    "Texto:\n",
    "```{text_1}```\n",
    "\"\"\"\n",
    "\n",
    "response = preguntar_gpt(prompt)\n",
    "display(Markdown(f\"**Respuesta GPT:** {response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"**Respuesta de LLAMA:** {preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt', prompt=prompt)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Few-shot prompting: Utiliza ejemplos para que el modelo entienda mejor lo que quieres."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:Teoría/02-Principios basicos de prompting.ipynb
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Respuesta GPT:** No se proporcionaron pasos."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Intento 1 fallido. Error: 500 Server Error: Internal Server Error for url: https://api.awanllm.com/v1/chat/completions\n",
      "No se pudo completar la solicitud después de varios intentos.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Respuesta de LLAMA:** None"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_1 = \"\"\"Los humanos son seres sociales por naturaleza y, por lo tanto, la comunicación es una parte esencial de la vida cotidiana. La comunicación efectiva puede ser verbal o no verbal, y ambas formas son igualmente importantes. Algunos estudios sugieren que el 93% de la comunicación es no verbal, lo que significa que el lenguaje corporal, las expresiones faciales y otros gestos juegan un papel crucial en la forma en que nos comunicamos. Por otro lado, la comunicación verbal también es fundamental, ya que nos permite expresar nuestros pensamientos, sentimientos y emociones de manera clara y concisa.\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Vas a recibir un texto delimitado por triples comillas.\n",
    "Si contiene una secuencia de instrucciones, reescribe esas instrucciones en el siguiente formato:\n",
    "\n",
    "Paso 1 - ...\\n\n",
    "Paso 2 - ...\\n\n",
    "…\n",
    "Paso N - ... \\n\n",
    "\n",
    "Si el texto no contiene una secuencia de instrucciones, entonces simplemente escribe \"No se proporcionaron pasos.\"\n",
    "\n",
    "Texto:\n",
    "```{text_1}```\n",
    "\"\"\"\n",
    "\n",
    "response = preguntar_gpt(prompt)\n",
    "display(Markdown(f\"**Respuesta GPT:** {response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"**Respuesta de LLAMA:** {preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt', prompt=prompt)}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
=======
   "execution_count": 11,
>>>>>>> origin/main:02-Principios basicos de prompting.ipynb
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Respuesta GPT:** No se proporcionaron pasos."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Respuesta de LLAMA:** No se proporcionan pasos."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_1 = \"\"\"Los humanos son seres sociales por naturaleza y, por lo tanto, la comunicación es una parte esencial de la vida cotidiana. La comunicación efectiva puede ser verbal o no verbal, y ambas formas son igualmente importantes. Algunos estudios sugieren que el 93% de la comunicación es no verbal, lo que significa que el lenguaje corporal, las expresiones faciales y otros gestos juegan un papel crucial en la forma en que nos comunicamos. Por otro lado, la comunicación verbal también es fundamental, ya que nos permite expresar nuestros pensamientos, sentimientos y emociones de manera clara y concisa.\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Vas a recibir un texto delimitado por triples comillas.\n",
    "Si contiene una secuencia de instrucciones, reescribe esas instrucciones en el siguiente formato:\n",
    "\n",
    "Paso 1 - ...\\n\n",
    "Paso 2 - ...\\n\n",
    "…\n",
    "Paso N - ... \\n\n",
    "\n",
    "Si el texto no contiene una secuencia de instrucciones, entonces simplemente escribe \"No se proporcionaron pasos.\"\n",
    "\n",
    "Texto:\n",
    "```{text_1}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "display(Markdown(f\"**Respuesta GPT:** {response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"**Respuesta de LLAMA:** {preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt', prompt=prompt)}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Respuesta GPT:** <abuelo>: La resiliencia es como el bambú, que se dobla con el viento pero nunca se quiebra. Es la capacidad de enfrentar los desafíos con valentía y perseverancia, de levantarse una y otra vez después de cada caída. Es la fuerza interior que nos permite seguir adelante, incluso en los momentos más difíciles. Recuerda siempre que, al igual que el bambú, tú también puedes doblarte pero nunca romperte."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Respuesta de LLAMA:** Abuelo, veo que mi hijo te ha pedido algo nuevo y emocionante. ¡Vamos allá!\n",
       "\n",
       "<abuelo>: La resiliencia es como el tronco de un árbol viejo, erosionado por las tormentas del tiempo. A medida que las tempestades golpean y golpean, el tronco se vuelve más ancho y más resistente, porque cada vez que cae una hoja o se desprenden ramas, el árbol reacciona creando nuevas defensas para protegerse. De igual manera, cuando la adversidad nos golpea, nuestra resiliencia se fortalece, permitiendo que nos adaptemos y crezcamos en la adversidad. Así que no temas, hijo mío, que la resiliencia no es la ausencia de dificultades, sino la capacidad de superarlas y seguir adelante, más fuerte y sabio."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Tu tarea es responder de manera consistente.\n",
    "\n",
    "<hijo>: Enséñame sobre la paciencia.\n",
    "\n",
    "<abuelo>: El río que talla el valle más profundo fluye desde una modesta fuente; la sinfonía más grandiosa se origina a partir de una sola nota; el tapiz más intrincado comienza con un hilo solitario.\n",
    "\n",
    "<hijo>: Enséñame sobre la resiliencia.\n",
    "\"\"\"\n",
    "response = preguntar_gpt(prompt)\n",
    "display(Markdown(f\"**Respuesta GPT:** {response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"**Respuesta de LLAMA:** {preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt', prompt=prompt)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principio 2: Darle tiempo al modelo para \"pensar\" en la respuesta.\n",
    "\n",
    "Táctica: Especifica los pasos requeridos para completar la tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Respuesta GPT para el prompt 1:** 1 - Mario y Sara se aventuran en busca de un tesoro perdido en un bosque tranquilo, pero terminan atrapados en trampas.\n",
      "\n",
      "2 - Mario et Sara se lancent à la recherche d'un trésor perdu dans une forêt tranquille, mais se retrouvent piégés.\n",
      "\n",
      "3 - Mario, Sara\n",
      "\n",
      "4 - {\n",
      "    \"french_summary\": \"Mario et Sara se lancent à la recherche d'un trésor perdu dans une forêt tranquille, mais se retrouvent piégés.\",\n",
      "    \"num_names\": 2\n",
      "}\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "**Respuesta de LLAMA para el prompt 1:** **Resumen del texto**\n",
      "\n",
      "Los hermanos Mario y Sara salen a buscar un tesoro en un bosque y accidentalmente activan una trampa, pero afortunadamente logran escapar sin graves daños y deciden seguir adelante con su búsqueda.\n",
      "\n",
      "**Traducción al francés**\n",
      "\n",
      "Les frères Mario et Sara partent à la recherche d'un trésor dans une forêt et accidentellement déclenchent une piège, mais heureusement ils parviennent à s'en échapper sans grands dommages et décident de continuer leur quête.\n",
      "\n",
      "**Lista de nombres en francés**\n",
      "\n",
      "* Mario\n",
      "* Sara\n",
      "\n",
      "**Objeto JSON**\n",
      "```\n",
      "{\n",
      "    \"french_summary\": \"Les frères Mario et Sara partent à la recherche d'un trésor dans une forêt et accidentellement déclenchent une piège, mais heureusement ils parviennent à s'en échapper sans grands dommages et décident de continuer leur quête.\",\n",
      "    \"num_names\": 2\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "En un tranquilo bosque, los hermanos Mario y Sara se aventuraron en busca de un antiguo tesoro perdido. Mientras caminaban entre los árboles, riendo y compartiendo historias, un ruido extraño los detuvo de repente. MArio, intrigado, se acercó para investigar y accidentalmente activó una trampa oculta. Una red se desplegó atrapándolo, y Sara, al intentar liberarlo, cayó en un foso cercano.\n",
    "\n",
    "Afortunadamente, ninguno de los dos resultó gravemente herido. Juntos, encontraron la manera de salir de sus respectivas trampas y regresaron a casa con algunas raspaduras y moretones. Sin embargo, en lugar de desanimarse, se abrazaron con alivio y se rieron de su mala suerte.\n",
    "\n",
    "Decidieron que la próxima vez serían más cuidadosos, pero su determinación por descubrir el tesoro perdido no disminuyó. Con una nueva perspectiva sobre la aventura, continuaron explorando el bosque con entusiasmo renovado, emocionados por lo que el destino les depararía.\n",
    "\"\"\"\n",
    "\n",
    "prompt_1 = f\"\"\"\n",
    "Realiza las siguientes acciones: \n",
    "1 - Resumir el siguiente texto delimitado por triple comillas con 1 frase.\n",
    "2 - Traduzca el resumen al francés.\n",
    "3 - Listar cada nombre en el resumen en francés.\n",
    "4 - Generar un objeto json que contenga lo siguiente\n",
    "claves: french_summary, num_names.\n",
    "\n",
    "Separa tus respuestas con saltos de línea.\n",
    "\n",
    "Texto:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = preguntar_gpt(prompt_1)\n",
    "print(f\"**Respuesta GPT para el prompt 1:** {response}\")\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "print(f\"**Respuesta de LLAMA para el prompt 1:** {preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt', prompt=prompt_1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pide el resultado en un formato específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Respuesta GPT para el prompt 2:** Resumen: En un bosque tranquilo, los hermanos Mario y Sara se aventuran en busca de un tesoro perdido, pero terminan atrapados en trampas antes de regresar a casa con raspaduras y moretones, decididos a seguir con su búsqueda.\n",
      "\n",
      "Traducción: Dans une forêt tranquille, les frères Mario et Sara s'aventurent à la recherche d'un trésor perdu, mais se retrouvent piégés avant de rentrer chez eux avec des égratignures et des bleus, déterminés à poursuivre leur quête.\n",
      "\n",
      "Nombres: Mario, Sara\n",
      "\n",
      "JSON de salida: {\"french_summary\": \"Dans une forêt tranquille, les frères Mario et Sara s'aventurent à la recherche d'un trésor perdu, mais se retrouvent piégés avant de rentrer chez eux avec des égratignures et des bleus, déterminés à poursuivre leur quête.\", \"num_names\": 2}\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "**Respuesta de LLAMA para el prompt 2:** Texto: <En un tranquilo bosque, los hermanos Mario y Sara se aventuraron en busca de un antiguo tesoro perdido.>\n",
      "\n",
      "Resumen: Los hermanos Mario y Sara se aventuran en busca de un tesoro perdido en un bosque y accidentalmente activan una trampa, pero salen indemnes y deciden continuar su búsqueda.\n",
      "\n",
      "Traducción: Les frères Mario et Sara s'aventurent à la recherche d'un trésor perdu dans une forêt et activent accidentellement une trappe, mais sortent indemnes et décident de continuer leur recherche.\n",
      "\n",
      "Nombres: Mario, Sara\n",
      "\n",
      "JSON de salida:\n",
      "{\n",
      "\"french_summary\": \"Les frères Mario et Sara s'aventurent à la recherche d'un trésor perdu dans une forêt et activent accidentellement une trappe, mais sortent indemnes et décident de continuer leur recherche.\",\n",
      "\"num_names\": 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt_2 = f\"\"\"\n",
    "tu tarea consiste en realizar las siguientes acciones: \n",
    "1 - Resumir el siguiente texto delimitado por <> con 1 frase.\n",
    "2 - Traduzcir el resumen al francés.\n",
    "3 - Listar cada nombre en el resumen en francés.\n",
    "4 - Dar salida a un objeto json que contenga las siguientes claves: french_summary, num_names.\n",
    "\n",
    "Utilice el siguiente formato:\n",
    "Texto: <texto a resumir>\n",
    "Resumen: <resumen>\n",
    "Traducción: <traducción del resumen>\n",
    "Nombres: <lista de nombres en resumen>\n",
    "JSON de salida: <json con resumen y número_nombres>\n",
    "\n",
    "Texto: <{text}>\n",
    "\"\"\"\n",
    "response = preguntar_gpt(prompt_2)\n",
    "print(f\"**Respuesta GPT para el prompt 2:** {response}\")\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "print(f\"**Respuesta de LLAMA para el prompt 2:** {preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt', prompt=prompt_2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Táctica 2: Pedir al modelo que elabore su propia solución antes de llegar a una conclusión precipitada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitaciones del modelo: Alucinaciones\n",
    "\n",
    "Apple es una compañía de tecnología real pero iCan no es un producto real de Apple. Sin embargo, el modelo puede alucinar que iCan es un producto real de Apple y devolvernos una respuesta que no es cierta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Respuesta GPT:** El iCan es el último dispositivo portátil de Apple que combina las funciones de un reloj inteligente, un monitor de actividad física y un asistente personal en un solo dispositivo. Con un diseño elegante y moderno, el iCan cuenta con una pantalla táctil de alta resolución que muestra notificaciones, mensajes, llamadas y otras funciones de forma clara y fácil de usar.\n",
       "\n",
       "Además, el iCan incluye sensores avanzados que monitorean la actividad física del usuario, como el ritmo cardíaco, la calidad del sueño, los pasos dados y las calorías quemadas. También cuenta con funciones de asistente personal que permiten al usuario realizar tareas como enviar mensajes, hacer llamadas, programar recordatorios y controlar dispositivos inteligentes en el hogar.\n",
       "\n",
       "El iCan se sincroniza con la aplicación Health de Apple, que permite al usuario llevar un registro de su actividad física, establecer metas de salud y recibir recomendaciones personalizadas para mejorar su bienestar. En resumen, el iCan es una innovación revolucionaria en tecnología de dispositivos portátiles que combina estilo, funcionalidad y conven"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Respuesta de LLAMA:** Disculpa, pero no hay un dispositivo llamado \"iCan\" lanzado por Apple. Es posible que estés pensando en otro producto o servicio de Apple o confundiendo información.\n",
       "\n",
       "Sin embargo, Apple ha lanzado varios productos y servicios recientemente, como el iPhone 13, el iPad Air (2022), el MacBook Air M1, el Apple Watch Series 7, entre otros. También ha mejorado y actualizado sus servicios como iCloud, Apple Music, Apple TV+, etc.\n",
       "\n",
       "Si necesitas información específica sobre algún producto o servicio de Apple, estaré feliz de ayudarte. ¡No dudes en preguntar!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Háblame sobre el iCan, la última innovación en tecnología de dispositivos portátiles de Apple.\n",
    "\"\"\"\n",
    "response = preguntar_gpt(prompt)\n",
    "display(Markdown(f\"**Respuesta GPT:** {response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"**Respuesta de LLAMA:** {preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt', prompt=prompt)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tu turno de experimentar!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
