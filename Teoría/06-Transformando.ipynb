{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformando\n",
    "\n",
    "En este notebook vamos a explorar cómo usar LLM para tareas de transformación de texto como traducción de idiomas, corrección de ortografía y gramática, ajuste de tono y conversión de formato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "import sys\n",
    "sys.path.append('../utils/')\n",
    "from funciones import preguntar_llama, preguntar_gpt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traducción de idiomas\n",
    "\n",
    "Los modelos de lenguaje, en este caso GPT, están entrenados con fuentes diversas en varios idiomas. Esto significa que pueden ser utilizados para traducir texto de un idioma a otro. Aunque no es su propósito principal, los modelos de lenguaje pueden ser utilizados para traducción de idiomas. Veamos sus capacidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Respuesta de GPT\n",
       "\"Excuse me, where is the train station?\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de LLAMA\n",
       "\"Excuse me, where is the train station?\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Traduce la siguiente frase al inglés: \"Perdona, ¿dónde está la estación de tren?\"\n",
    "\"\"\"\n",
    "response = preguntar_gpt(prompt)\n",
    "display(Markdown(f\"### Respuesta de GPT\\n{response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"### Respuesta de LLAMA\\n{preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt sin preámbulos explicativos ni resúmenes finales.', prompt)}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Respuesta de GPT\n",
       "La frase está escrita en francés."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de LLAMA\n",
       "Francés."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Dime en qué idioma está escrita la siguiente frase: \"Bonjour, comment ça va?\"\n",
    "\"\"\"\n",
    "response = preguntar_gpt(prompt)\n",
    "display(Markdown(f\"### Respuesta de GPT\\n{response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"### Respuesta de LLAMA\\n{preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt sin preámbulos explicativos ni resúmenes finales.', prompt)}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Respuesta de GPT\n",
       "Inglés: \"Would you be so kind as to bring me the potatoes?\"\n",
       "Coreano: \"감자를 가져다 주실 수 있나요?\"\n",
       "Español de Argentina: \"¿Me traerías las papas, por favor?\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de LLAMA\n",
       "Here are the translations:\n",
       "\n",
       "* English: \"Would you mind bringing me some potatoes?\"\n",
       "* Korean: \"\" (joh-eun neo-keu-si jom pat-ta-reul ga-ju-se-yo)\n",
       "* Spanish (Argentine): \"¿Me harías el favor de traerme las papas?\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Traduce la siguiente frase al inglés, al coreano y al Español de Argentina: \"¿Tendrías la amabilidad de acercarme las patatas?\"\n",
    "\"\"\"\n",
    "response = preguntar_gpt(prompt)\n",
    "display(Markdown(f\"### Respuesta de GPT\\n{response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"### Respuesta de LLAMA\\n{preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt sin preámbulos explicativos ni resúmenes finales.', prompt)}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Respuesta de GPT\n",
       "Formal: ¿Le gustaría ordenar una almohada?\n",
       "Informal: ¿Te gustaría pedir una almohada?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de LLAMA\n",
       "* Formal: ¿Le gustaría ordenar una almohada?\n",
       "* Informal: ¿Quieres pedir una almohada?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Traduce la siguiente frase al Español formal y al informal:\n",
    "'Would you like to order a pillow?'\n",
    "\"\"\"\n",
    "response = preguntar_gpt(prompt)\n",
    "display(Markdown(f\"### Respuesta de GPT\\n{response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"### Respuesta de LLAMA\\n{preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt sin preámbulos explicativos ni resúmenes finales.', prompt)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traductor universal\n",
    "\n",
    "Imagine que está a cargo de IT (Information Technology) en una gran empresa de comercio electrónico multinacional. Los usuarios le están enviando mensajes con problemas de IT en todos sus idiomas nativos. Su personal es de todo el mundo y solo habla sus idiomas nativos. ¡Necesita un traductor universal!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_inputs = [\n",
    "    \"La cámara de mi movil no funciona\",\n",
    "    \"How can I fix my wifi?\",\n",
    "    \"Il mio computer non si accende\",\n",
    "    \"La baterie de mon téléphone ne se charge pas\",\n",
    "    \"Moj telefon se ne uključuje\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mensaje original (Español): La cámara de mi movil no funciona\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de GPT\n",
       "Español: \"La cámara de mi móvil no funciona\"\n",
       "Inglés: \"The camera on my phone is not working\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de LLAMA\n",
       "Spanish:\n",
       "Mi teléfono no tiene función de cámara.\n",
       "\n",
       "English:\n",
       "My phone's camera is not working."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Mensaje original (Está escrito en inglés.): How can I fix my wifi?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de GPT\n",
       "- Español: ¿Cómo puedo arreglar mi wifi?\n",
       "- Inglés: How can I fix my wifi?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de LLAMA\n",
       "**Español:** ¿Cómo puedo reparar mi WiFi?\n",
       "\n",
       "**Inglés:** How can I fix my Wi-Fi?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Mensaje original (Italiano): Il mio computer non si accende\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de GPT\n",
       "Español: Mi computadora no se enciende\n",
       "Inglés: My computer won't turn on"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de LLAMA\n",
       "**Italiano**: El mio computer no se enciende.\n",
       "\n",
       "**Inglés**: My computer won't turn on."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Mensaje original (Francés): La baterie de mon téléphone ne se charge pas\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de GPT\n",
       "Español: \"La batería de mi teléfono no se carga\"\n",
       "Inglés: \"My phone battery is not charging\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de LLAMA\n",
       "**Español:** La batería de mi teléfono no se carga.\n",
       "\n",
       "**Inglés:** My phone's battery won't charge."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Mensaje original (Está escrito en croata.): Moj telefon se ne uključuje\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de GPT\n",
       "Español: Mi teléfono no se enciende\n",
       "Inglés: My phone is not turning on"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de LLAMA\n",
       "**Español:** Mi teléfono no se enciende.\n",
       "\n",
       "**Inglés:** My phone won't turn on."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for input in user_inputs:\n",
    "    prompt = f\"Dime en qué idioma está escrito: ```{input}```\"\n",
    "    lang = preguntar_gpt(prompt)\n",
    "    print(f\"Mensaje original ({lang}): {input}\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Traduce el siguiente texto al Español y al Inglés: ```{input}```\n",
    "    \"\"\"\n",
    "    response = preguntar_gpt(prompt)\n",
    "    display(Markdown(f\"### Respuesta de GPT\\n{response}\"))\n",
    "    display(Markdown(f\"### Respuesta de LLAMA\\n{preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt sin preámbulos explicativos ni resúmenes finales.', prompt)}\"))\n",
    "    print(\"\\n---------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modificación del tono\n",
    "\n",
    "La escritura puede variar según el público objetivo. ChatGPT puede producir diferentes tonos. Por ejemplo, puede convertir un texto formal en uno informal o viceversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Respuesta de GPT\n",
       "Estimado/a,\n",
       "\n",
       "Le presento a Rafa, quien puede brindarle asistencia con el tema relacionado al automóvil. Por favor, no dude en contactarlo para obtener ayuda.\n",
       "\n",
       "Saludos cordiales."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de LLAMA\n",
       "Estimado [Nombre del destinatario],\n",
       "\n",
       "Le transmito su contacto con Rafael, quien se encuentra disponible para brindar apoyo en relación con el proyecto mencionado.\n",
       "\n",
       "Atentamente,\n",
       "[Tu nombre]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Traduce la siguiente frase del español informal a un lenguaje de negocios en español en un correo de trabajo: \"Tio, este es Rafa, puedes llamarlo para que te eche una mano con la movida esa del coche\"\n",
    "\"\"\"\n",
    "response = preguntar_gpt(prompt)\n",
    "display(Markdown(f\"### Respuesta de GPT\\n{response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"### Respuesta de LLAMA\\n{preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt sin preámbulos explicativos ni resúmenes finales.', prompt)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversión de formato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Respuesta de GPT\n",
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "    <title>Empleados de restaurante</title>\n",
       "</head>\n",
       "<body>\n",
       "    <h1>Empleados de restaurante</h1>\n",
       "    <table>\n",
       "        <tr>\n",
       "            <th>Nombre</th>\n",
       "            <th>Email</th>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Shyam</td>\n",
       "            <td>shyamjaiswal@gmail.com</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Bob</td>\n",
       "            <td>bob32@gmail.com</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Jai</td>\n",
       "            <td>jai87@gmail.com</td>\n",
       "        </tr>\n",
       "    </table>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de LLAMA\n",
       "```\n",
       "<html>\n",
       "<head>\n",
       "    <title>Empleados del Restaurante</title>\n",
       "</head>\n",
       "<body>\n",
       "    <h1>Empleados del Restaurante</h1>\n",
       "    <table border=\"1\">\n",
       "        <tr>\n",
       "            <th>Nombre</th>\n",
       "            <th>Email</th>\n",
       "        </tr>\n",
       "        {% for empleado in empleados_restaurante %}\n",
       "        <tr>\n",
       "            <td>{{ empleado.nombre }}</td>\n",
       "            <td>{{ empleado.email }}</td>\n",
       "        </tr>\n",
       "        {% endfor %}\n",
       "    </table>\n",
       "</body>\n",
       "</html>\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_json = { \"empleados_restaurante\" :[ \n",
    "    {\"nombre\": \"Shyam\", \"email\": \"shyamjaiswal@gmail.com\"},\n",
    "    {\"name\":\"Bob\", \"email\":\"bob32@gmail.com\"},\n",
    "    {\"name\":\"Jai\", \"email\":\"jai87@gmail.com\"}\n",
    "]}\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Traduce el siguiente diccionario python de JSON a una  HTML con encabezados de columna y título: {data_json}\n",
    "\"\"\"\n",
    "response = preguntar_gpt(prompt)\n",
    "display(Markdown(f\"### Respuesta de GPT\\n{response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"### Respuesta de LLAMA\\n{preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt sin preámbulos explicativos ni resúmenes finales.', prompt)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrección de ortografía y gramática"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta de GPT\n",
      "La niña de los cachorros blancos y negros tiene una pelota.\n",
      "Yolanda tiene su cuaderno.\n",
      "Va a ser un día largo. ¿El coche necesita que le cambien el aceite?\n",
      "Ahí va mi libertad.\n",
      "Vas a necesitar tu cuaderno.\n",
      "Esa medicina afecta mi capacidad para dormir. ¿Has oído hablar del efecto mariposa?\n",
      "This phrase is to check ChatGPT for spelling ability.\n",
      "\n",
      "\n",
      "\n",
      "Respuesta de LLAMA\n",
      "La niña de los cachorros blancos y negros tiene una pelota.\n",
      "\"Yolanda tiene su cuadro.\"\n",
      "\"Será un día largo. El coche necesita que le cambien el aceite.\"\n",
      "\"Aquí va mi libertad\"\n",
      "\"Debes necesitar tu cuaderno\"\n",
      "La versión corregida del texto sería:\n",
      "\n",
      "\"Esta medicina afecta mi capacidad para dormir. He oído hablar del efecto mariposa.\"\n",
      "\"This phrase is to check chatGPT's spelling ability.\"\n"
     ]
    }
   ],
   "source": [
    "texto = [ \n",
    "  \"La niña de los cachorros blancos y negros tiene una pelota\", \n",
    "  \"Yolanda tiene su cuadeno\", \n",
    "  \"Va a ser un dia largo. El coche necesita que le cambien el aceite?\", \n",
    "  \"Ahi va mi livertad\", \n",
    "  \"Vas a necesitar tu cuaderno\", \n",
    "  \"Esa medicina afecta mi capacidad para dormir. ¿As oído hablar del efecto mariposa?\",\n",
    "  \"This phrase is to cherck chatGPT for spelling abilitty\"\n",
    "]\n",
    "print('Respuesta de GPT')\n",
    "for t in texto:\n",
    "    prompt = f\"\"\"Revisa y corrige el siguiente texto. Vuelve a escribir una versión corregida sin faltas de ortografías y gramaticalmente correcta.\n",
    "    ```{t}```\"\"\"\n",
    "    response = preguntar_gpt(prompt)\n",
    "    print(response)\n",
    "print(\"\\n\\n\")\n",
    "print('Respuesta de LLAMA')\n",
    "for t in texto:\n",
    "    prompt = f\"\"\"Revisa y corrige el siguiente texto. Vuelve a escribir una versión corregida sin faltas de ortografías y gramaticalmente correcta.\n",
    "    ```{t}```\"\"\"\n",
    "    response = preguntar_gpt(prompt)\n",
    "    print(preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt sin preámbulos explicativos ni resúmenes finales.', prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Respuesta de GPT\n",
       "Primero compré la versión de 2 pesas a un muy buen precio, aunque actualmente parece que han subido el precio, por lo que les recomendaría esperar a una oferta. Al recibir solo una de las pesas me asusté, pero luego me di cuenta de que otro transportista me entregaría la otra. Fue un poco extraño que Amazon me entregara una y SEUR la otra, pero al final todo salió bien. En cuanto al uso, todo ha sido perfecto, ya que se puede cambiar de peso al instante. Sin embargo, a veces se traba un poco y me preocupa que un día deje de funcionar. Aunque los pesos no ajustables nunca se rompen, considero que esta es una inversión para toda la vida. Por ahora todo va bien, solo espero que el mango no deje de funcionar en el futuro."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de LLAMA\n",
       "Aquí te dejo la reseña revisada:\n",
       "\n",
       "\"Me compré la versión de 2 kg a un buen precio. Creo que han aumentado el precio desde entonces, así que les recomiendo esperar una oferta. Después de recibir mi pedido, solo recibí uno de los dos productos, lo que me sorprendió. Sin embargo, otro transportista se encargó de enviarme el segundo producto. Es extraño que Amazon enviara uno con SEUR y el otro con otro transportista, pero bueno. En cuanto al uso, todo ha sido perfecto, excepto que a veces se atasca y cambio de peso instantáneamente. Me preocupa que un día se atase definitivamente y dejar de funcionar, ya que los productos no ajustables inevitablemente se rompen y esto es una inversión para toda la vida. Por ahora, todo va bien.\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Primero me compre la versión de 2 pesas a un muy buen precio, creo que actualmente lo subieron más de precio así que les recomiendo que se esperen una oferta. Después me llego solo uno y me asuste pero tranquilos, otro transportista les entregará el otro, aunque es raro que Amazon me entregó uno y el otro me lo entrego SEUR, muy raro pero bueno. Al uso todo perfecto porque al instante cambias de peso pero a veces se traba y me da miedo que un día se trabe y que deje de funcionar porque es obvio que los que no son ajustables nunca se van a romper y es una inversión para toda la vida pero esta me da miedo que deje de funcionar el mango pero por mientras todo bien :)\n",
    "\"\"\"\n",
    "prompt = f\"Revisa y corrije esta reseña: ```{text}```\"\n",
    "response = preguntar_gpt(prompt)\n",
    "display(Markdown(f\"### Respuesta de GPT\\n{response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"### Respuesta de LLAMA\\n{preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt sin preámbulos explicativos ni resúmenes finales.', prompt)}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting redlines\n",
      "  Downloading redlines-0.4.2-py3-none-any.whl (8.0 kB)\n",
      "Collecting click<9.0.0,>=8.1.3\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rich<14.0.0,>=13.3.5\n",
      "  Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rich-click<2.0.0,>=1.6.1\n",
      "  Downloading rich_click-1.8.2-py3-none-any.whl (34 kB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.11/site-packages (from rich<14.0.0,>=13.3.5->redlines) (2.18.0)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.11/site-packages (from rich-click<2.0.0,>=1.6.1->redlines) (4.12.1)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: mdurl, click, markdown-it-py, rich, rich-click, redlines\n",
      "Successfully installed click-8.1.7 markdown-it-py-3.0.0 mdurl-0.1.2 redlines-0.4.2 rich-13.7.1 rich-click-1.8.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install redlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Primero <span style='color:red;font-weight:700;text-decoration:line-through;'>me compre </span><span style='color:green;font-weight:700;'>compré </span>la versión de 2 pesas a un muy buen precio, <span style='color:red;font-weight:700;text-decoration:line-through;'>creo </span><span style='color:green;font-weight:700;'>aunque actualmente parece </span>que <span style='color:red;font-weight:700;text-decoration:line-through;'>actualmente </span><span style='color:green;font-weight:700;'>han subido el precio, por </span>lo <span style='color:red;font-weight:700;text-decoration:line-through;'>subieron más de precio así </span>que les <span style='color:red;font-weight:700;text-decoration:line-through;'>recomiendo que se esperen </span><span style='color:green;font-weight:700;'>recomendaría esperar a </span>una oferta. <span style='color:red;font-weight:700;text-decoration:line-through;'>Después </span><span style='color:green;font-weight:700;'>Al recibir solo una de las pesas </span>me <span style='color:red;font-weight:700;text-decoration:line-through;'>llego solo uno y </span><span style='color:green;font-weight:700;'>asusté, pero luego </span>me <span style='color:red;font-weight:700;text-decoration:line-through;'>asuste pero tranquilos, </span><span style='color:green;font-weight:700;'>di cuenta de que </span>otro transportista <span style='color:red;font-weight:700;text-decoration:line-through;'>les entregará el otro, aunque es raro </span><span style='color:green;font-weight:700;'>me entregaría la otra. Fue un poco extraño </span>que Amazon me <span style='color:red;font-weight:700;text-decoration:line-through;'>entregó uno </span><span style='color:green;font-weight:700;'>entregara una </span>y <span style='color:red;font-weight:700;text-decoration:line-through;'>el otro me lo entrego SEUR, muy raro </span><span style='color:green;font-weight:700;'>SEUR la otra, </span>pero <span style='color:red;font-weight:700;text-decoration:line-through;'>bueno. Al uso </span><span style='color:green;font-weight:700;'>al final </span>todo <span style='color:red;font-weight:700;text-decoration:line-through;'>perfecto porque </span><span style='color:green;font-weight:700;'>salió bien. En cuanto </span>al <span style='color:red;font-weight:700;text-decoration:line-through;'>instante cambias </span><span style='color:green;font-weight:700;'>uso, todo ha sido perfecto, ya que se puede cambiar </span>de peso <span style='color:red;font-weight:700;text-decoration:line-through;'>pero </span><span style='color:green;font-weight:700;'>al instante. Sin embargo, </span>a veces se traba <span style='color:green;font-weight:700;'>un poco </span>y me <span style='color:red;font-weight:700;text-decoration:line-through;'>da miedo </span><span style='color:green;font-weight:700;'>preocupa </span>que un día <span style='color:red;font-weight:700;text-decoration:line-through;'>se trabe y que </span>deje de <span style='color:red;font-weight:700;text-decoration:line-through;'>funcionar porque es obvio que </span><span style='color:green;font-weight:700;'>funcionar. Aunque </span>los <span style='color:red;font-weight:700;text-decoration:line-through;'>que </span><span style='color:green;font-weight:700;'>pesos </span>no <span style='color:red;font-weight:700;text-decoration:line-through;'>son </span>ajustables nunca se <span style='color:red;font-weight:700;text-decoration:line-through;'>van a romper y </span><span style='color:green;font-weight:700;'>rompen, considero que esta </span>es una inversión para toda la <span style='color:red;font-weight:700;text-decoration:line-through;'>vida pero esta me da miedo </span><span style='color:green;font-weight:700;'>vida. Por ahora todo va bien, solo espero </span>que <span style='color:green;font-weight:700;'>el mango no </span>deje de funcionar <span style='color:green;font-weight:700;'>en </span>el <span style='color:red;font-weight:700;text-decoration:line-through;'>mango pero por mientras todo bien :)</span><span style='color:green;font-weight:700;'>futuro.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from redlines import Redlines\n",
    "\n",
    "diff = Redlines(text,response)\n",
    "display(Markdown(diff.output_markdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Respuesta de GPT\n",
       "# Reseña de las pesas ajustables\n",
       "\n",
       "En primer lugar, adquirí la versión de 2 pesas a un precio muy atractivo, aunque parece que actualmente han aumentado su valor, por lo que recomendaría esperar a una oferta. Al recibir solo una de las pesas, inicialmente me preocupé, pero posteriormente llegó la otra a través de un transportista distinto, lo cual resultó un tanto inusual ya que Amazon entregó una y la otra fue entregada por SEUR. \n",
       "\n",
       "En cuanto al uso, todo ha sido perfecto, ya que permite cambiar de peso de forma instantánea. Sin embargo, en ocasiones se traba, lo cual me genera cierta preocupación de que pueda dejar de funcionar en algún momento. Aunque es evidente que las pesas no ajustables nunca se romperán y representan una inversión a largo plazo, en este caso específico me preocupa que el mecanismo de ajuste pueda fallar. Por el momento, todo funciona correctamente.\n",
       "\n",
       "En conclusión, las pesas ajustables han demostrado ser una opción conveniente y versátil, a pesar de algunas preocupaciones sobre su durabilidad a largo plazo. Recomiendo considerar la posibilidad de adquirirlas en oferta para obtener el mejor valor por su dinero.\n",
       "\n",
       "Referencia:\n",
       "Apellido, A. (Año). Reseña de las pesas ajustables. Revista de Equipamiento Deportivo, 10(2), 45-48."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Respuesta de LLAMA\n",
       "**Corregida**\n",
       "\n",
       "La experiencia con mi compra de una báscula de dos pesos fue positiva, especialmente considerando el precio competitivo que pagué. Sin embargo, me parece recomendable esperar una oferta antes de comprar, ya que supongo que el precio ha aumentado desde entonces.\n",
       "\n",
       "Me llegaron los productos separados, con uno de ellos siendo enviado por SEUR y el otro por otro transportista. Esto resultó extraño, pero no hubo problemas con la entrega. Aunque la experiencia fue inusual, no tuve problemas para utilizar la báscula.\n",
       "\n",
       "En cuanto al uso, todo funciona correctamente, exceptuando algunos inconvenientes ocasionales cuando el peso cambia rápidamente y la báscula se trabaja. Me preocupa que este problema empeore con el tiempo y afecte la funcionalidad de la báscula, ya que no estoy seguro de si puedo repararla o cambiarla si sucede. Sin embargo, por ahora, todo sigue bien y espero que sea una inversión valiosa para largo plazo."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Revisa y corrije esta reseña y vuelve a escribir una versión corregida sin faltas de ortografías y gramaticalmente correcta teniendo en cuenta las normas APA y la estructura de un ensayo académico. La salida debe ser en formato markdown.\n",
    "\n",
    "Texto: ```{text}```\n",
    "\"\"\"\n",
    "response = preguntar_gpt(prompt)\n",
    "display(Markdown(f\"### Respuesta de GPT\\n{response}\"))\n",
    "print(\"\\n---------------------------------------------\\n\")\n",
    "display(Markdown(f\"### Respuesta de LLAMA\\n{preguntar_llama('Eres un asistente de IA cuyo trabajo es responder a lo que te está pidiendo el usuario de la forma más fiel al prompt sin preámbulos explicativos ni resúmenes finales.', prompt)}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
