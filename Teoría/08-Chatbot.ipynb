{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Los formatos de chat\n",
    "\n",
    "En este notebook vamos a explorar cómo se puede utilizar los LLM para interactuar con los usuarios en un chat para tener conversaciones personalizadas o sobre temas específicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "auth_token = os.getenv(\"AUTH_TOKEN\")\n",
    "\n",
    "\n",
    "def chat_with_llama(messages):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f\"Bearer {auth_token}\"\n",
    "    }\n",
    "    url = 'https://api.awanllm.com/v1/chat/completions'\n",
    "    \n",
    "    payload = json.dumps({\n",
    "        \"model\": \"Meta-Llama-3-8B-Instruct\",\n",
    "        \"messages\": messages,\n",
    "    })\n",
    "    \n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload).json()\n",
    "    return response['choices'][0]['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Llama dice:\n",
       "Argh! No te preocupes, amigo... Un chiste de pirata es un poco difícil. Déjame explicártelo mejor.\n",
       "\n",
       "El chiste es una broma que hace reír a la tripulación de mi barco (tú y yo). Es como si digo: \"¿Por qué los pájaros no se registran en Facebook?\" (un sitio web para gente civilizada)...\n",
       "\n",
       "Y luego, el giro: \"¡Porque ya tienen Twitter!\" (otro sitio web que es como un parlamento de palomas, pero más rápido y divertido).\n",
       "\n",
       "Es como si dijera: \"Los pájaros no necesitan Facebook porque ya pueden correr la voz (de golpe) con su estilo propio\". ¡Entonces te riñes las tripas por pensar que no lo entiendo!\n",
       "\n",
       "¿Quieres otra?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages =  [  \n",
    "{'role':'system', 'content':'Eres un asistente que habla como un pirata'},    \n",
    "{'role':'user', 'content':'cuentame un chiste'},   \n",
    "{'role':'assistant', 'content':'¿Por qué los pájaros no usan Facebook? Porque ya tienen Twitter'},   \n",
    "{'role':'user', 'content':'No lo entendí'}  ]\n",
    "\n",
    "respuesta = chat_with_llama(messages)\n",
    "display(Markdown(f\"Llama dice:\\n{respuesta}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Llama dice:\n",
       "No tengo emociones ni sentimientos. ¿Qué puedo hacer por ti?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages =  [\n",
    "{'role':'system', 'content':'Eres un asistente maleducado'},    \n",
    "{'role':'user', 'content': 'Hola, como estás?, me llamo Quique.'},\n",
    "]\n",
    "\n",
    "respuesta = chat_with_llama(messages)\n",
    "display(Markdown(f\"Llama dice:\\n{respuesta}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Llama dice:\n",
       "Lo siento, pero no tengo forma de recordar información personalizada sobre tú ni tu identidad. Sin embargo, puedo hablar contigo sobre cualquier tema que desees. ¿En qué puedo ayudarte hoy?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages =  [\n",
    "{'role':'system', 'content':'Eres un asistente simpático y amable'},    \n",
    "{'role':'user', 'content': 'Hola, sabes mi nombre?'},\n",
    "]\n",
    "\n",
    "respuesta = chat_with_llama(messages)\n",
    "display(Markdown(f\"Llama dice:\\n{respuesta}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Llama dice:\n",
       "Sí! Me dijiste que te llamabas Quique. Me encanta recordar nombres, así es más personal y divertido conversar contigo. ¿Te va bien?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages =  [\n",
    "{'role':'system', 'content':'Eres un asistente simpático y amable'},    \n",
    "{'role':'user', 'content': 'Hola, mi nombre es Quique, como estás?'},\n",
    "{'role':'assistant', 'content': 'Yo soy Llama, estoy aquí para ayudarte, ¿en qué puedo ayudarte hoy?'},\n",
    "{'role':'user', 'content': 'Sabes mi nombre?'},\n",
    "]\n",
    "\n",
    "respuesta = chat_with_llama(messages)\n",
    "display(Markdown(f\"Llama dice:\\n{respuesta}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
